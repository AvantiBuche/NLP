{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf72733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW- Bay Of Words\n",
    "#This is only word classification not generation \n",
    "#All words provide same importance, it does not preserve sementic information\n",
    "\n",
    "paragraph = \"\"\"Thank you all so very much. Thank you to the Academy. Thank you to all of you in this room. I have to congratulate the other incredible nominees this year. The Revenant was the product of the tireless efforts of an unbelievable cast and crew. First off, to my brother in this endeavor, Mr. Tom Hardy. Tom, your talent on screen can only be surpassed by your friendship off screen â¦ thank you for creating a transcendent cinematic experience. Thank you to everybody at Fox and New Regency â¦ my entire team. I have to thank everyone from the very onset of my career â¦ To my parents; none of this would be possible without you. And to my friends, I love you dearly; you know who you are.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fafa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you all so very much. Thank you to the Academy. Thank you to all of you in this room. I have to congratulate the other incredible nominees this year. The Revenant was the product of the tireless efforts of an unbelievable cast and crew. First off, to my brother in this endeavor, Mr. Tom Hardy. Tom, your talent on screen can only be surpassed by your friendship off screen â\\x80¦ thank you for creating a transcendent cinematic experience. Thank you to everybody at Fox and New Regency â\\x80¦ my entire team. I have to thank everyone from the very onset of my career â\\x80¦ To my parents; none of this would be possible without you. And to my friends, I love you dearly; you know who you are.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78663d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e975ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e98db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank you all so very much.',\n",
       " 'Thank you to the Academy.',\n",
       " 'Thank you to all of you in this room.',\n",
       " 'I have to congratulate the other incredible nominees this year.',\n",
       " 'The Revenant was the product of the tireless efforts of an unbelievable cast and crew.',\n",
       " 'First off, to my brother in this endeavor, Mr. Tom Hardy.',\n",
       " 'Tom, your talent on screen can only be surpassed by your friendship off screen â\\x80¦ thank you for creating a transcendent cinematic experience.',\n",
       " 'Thank you to everybody at Fox and New Regency â\\x80¦ my entire team.',\n",
       " 'I have to thank everyone from the very onset of my career â\\x80¦ To my parents; none of this would be possible without you.',\n",
       " 'And to my friends, I love you dearly; you know who you are.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a900266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4716f79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank you all so very much ',\n",
       " 'thank you to the academy ',\n",
       " 'thank you to all of you in this room ',\n",
       " 'i have to congratulate the other incredible nominees this year ',\n",
       " 'the revenant was the product of the tireless efforts of an unbelievable cast and crew ',\n",
       " 'first off to my brother in this endeavor mr tom hardy ',\n",
       " 'tom your talent on screen can only be surpassed by your friendship off screen â thank you for creating a transcendent cinematic experience ',\n",
       " 'thank you to everybody at fox and new regency â my entire team ',\n",
       " 'i have to thank everyone from the very onset of my career â to my parents none of this would be possible without you ',\n",
       " 'and to my friends i love you dearly you know who you are ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(datasets)):\n",
    "    datasets[i] = datasets[i].lower()\n",
    "    datasets[i] = re.sub(r'\\W',' ',datasets[i])\n",
    "    datasets[i] = re.sub(r'\\s+',' ',datasets[i])\n",
    "    \n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ff81fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bbac0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thank': 6,\n",
       " 'you': 10,\n",
       " 'all': 2,\n",
       " 'so': 1,\n",
       " 'very': 2,\n",
       " 'much': 1,\n",
       " 'to': 8,\n",
       " 'the': 6,\n",
       " 'academy': 1,\n",
       " 'of': 5,\n",
       " 'in': 2,\n",
       " 'this': 4,\n",
       " 'room': 1,\n",
       " 'i': 3,\n",
       " 'have': 2,\n",
       " 'congratulate': 1,\n",
       " 'other': 1,\n",
       " 'incredible': 1,\n",
       " 'nominees': 1,\n",
       " 'year': 1,\n",
       " 'revenant': 1,\n",
       " 'was': 1,\n",
       " 'product': 1,\n",
       " 'tireless': 1,\n",
       " 'efforts': 1,\n",
       " 'an': 1,\n",
       " 'unbelievable': 1,\n",
       " 'cast': 1,\n",
       " 'and': 3,\n",
       " 'crew': 1,\n",
       " 'first': 1,\n",
       " 'off': 2,\n",
       " 'my': 5,\n",
       " 'brother': 1,\n",
       " 'endeavor': 1,\n",
       " 'mr': 1,\n",
       " 'tom': 2,\n",
       " 'hardy': 1,\n",
       " 'your': 2,\n",
       " 'talent': 1,\n",
       " 'on': 1,\n",
       " 'screen': 2,\n",
       " 'can': 1,\n",
       " 'only': 1,\n",
       " 'be': 2,\n",
       " 'surpassed': 1,\n",
       " 'by': 1,\n",
       " 'friendship': 1,\n",
       " 'â': 3,\n",
       " 'for': 1,\n",
       " 'creating': 1,\n",
       " 'a': 1,\n",
       " 'transcendent': 1,\n",
       " 'cinematic': 1,\n",
       " 'experience': 1,\n",
       " 'everybody': 1,\n",
       " 'at': 1,\n",
       " 'fox': 1,\n",
       " 'new': 1,\n",
       " 'regency': 1,\n",
       " 'entire': 1,\n",
       " 'team': 1,\n",
       " 'everyone': 1,\n",
       " 'from': 1,\n",
       " 'onset': 1,\n",
       " 'career': 1,\n",
       " 'parents': 1,\n",
       " 'none': 1,\n",
       " 'would': 1,\n",
       " 'possible': 1,\n",
       " 'without': 1,\n",
       " 'friends': 1,\n",
       " 'love': 1,\n",
       " 'dearly': 1,\n",
       " 'know': 1,\n",
       " 'who': 1,\n",
       " 'are': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#histrogram\n",
    "\n",
    "word2count = {} #this is a empty dictionary \n",
    "for data in datasets: # 'thank you to the academy '\n",
    "    words = nltk.word_tokenize(data)# [thank, you, to, the, academy]\n",
    "    for word in words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "            \n",
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64c9adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'to',\n",
       " 'thank',\n",
       " 'the',\n",
       " 'of',\n",
       " 'my',\n",
       " 'this',\n",
       " 'i',\n",
       " 'and',\n",
       " 'â',\n",
       " 'all',\n",
       " 'very',\n",
       " 'in',\n",
       " 'have',\n",
       " 'off',\n",
       " 'tom',\n",
       " 'your',\n",
       " 'screen',\n",
       " 'be',\n",
       " 'so']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "#to get top 20 keywords \n",
    "freq_words = heapq.nlargest(20,word2count,key=word2count.get)\n",
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc8b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank you all so very much ',\n",
       " 'thank you to the academy ',\n",
       " 'thank you to all of you in this room ',\n",
       " 'i have to congratulate the other incredible nominees this year ',\n",
       " 'the revenant was the product of the tireless efforts of an unbelievable cast and crew ',\n",
       " 'first off to my brother in this endeavor mr tom hardy ',\n",
       " 'tom your talent on screen can only be surpassed by your friendship off screen â thank you for creating a transcendent cinematic experience ',\n",
       " 'thank you to everybody at fox and new regency â my entire team ',\n",
       " 'i have to thank everyone from the very onset of my career â to my parents none of this would be possible without you ',\n",
       " 'and to my friends i love you dearly you know who you are ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f855f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for data in datasets: # thank you all so very much\n",
    "    vector = []\n",
    "    for word in freq_words:\n",
    "        if word in nltk.word_tokenize(data):\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    X.append(vector)\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a30f40fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X) #convert to array\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "babf5733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4233b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can use it as input but we can only use it in word classification not as generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b389517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
